# ARIA â€” Space Rider Mission Control Agent

*An offline, memory-augmented reasoning assistant for parafoil landing decision support â€” powered by GPT-OSS on Groq.*

**Category:** Best Local Agent (secondary: For Humanity)  
**Tagline:** Memory + safety gates + human-in-the-loop â†’ measurably safer landings on the *second* run.

---

## Why this matters

Space missions face comms gaps, uncertainty, and time pressure. ARIA shows how a small open model (gpt-oss-20b) can:
- **Retrieve procedures & lessons**, reason over telemetry, and
- **Propose safe, auditable next actions** with **risk** and **confidence**, while
- **Improving across runs** via episodicâ†’semantic memory â€” **no fine-tuning**.

We focus the demo on **AI reasoning, memory, and human-AI collaboration**. Telemetry is **pre-recorded** to keep the build reproducible and fully offline.

---

## Whatâ€™s included

- **Playback Service** â€” streams CSV telemetry at real time (20 Hz) and emits 1 Hz â€œreasoningâ€ ticks.
- **Memory Fabric** â€” SQLite + FTS5 (episodic log, semantic lessons, docs RAG, working memory).
- **Safety Gate** â€” redlines (bank, crosswind, flare window, descent rate) + confidence fusion.
- **ARIA Planner** â€” Groq OpenAI-compatible call to GPT-OSS (20B by default).
- **Human-AI UI** â€” Plan card (risk & confidence), Approve/Modify/Reject, Timeline, Before/After metrics.

---
## ğŸ“ Repository Structure

```bash
aria-space-rider/
â”œâ”€ README.md
â”œâ”€ .env.example
â”œâ”€ Makefile
â”œâ”€ data/
â”‚  â”œâ”€ telemetry/
â”‚  â””â”€ docs/
â”‚     â”œâ”€ space_rider_manual/
â”‚     â””â”€ processed/                 # .md from PyMuPDF4LLM
â”‚
â”œâ”€ backend/
â”‚  â”œâ”€ requirements.txt
â”‚  â”œâ”€ app.py                        # FastAPI app + startup
â”‚  â”œâ”€ settings.py                   # env & config
â”‚  â”œâ”€ api/
â”‚  â”‚  â”œâ”€ routes_knowledge.py 
â”‚  â”‚  â”œâ”€ routes_playback.py         # start/stop/list scenarios
â”‚  â”‚  â”œâ”€ routes_plan.py             # approve/modify/reject; stream plan SSE
â”‚  â”‚  â”œâ”€ routes_events.py           # SSE: ticks, anomalies, decisions
â”‚  â”‚  â””â”€ routes_admin.py            # reset memory, ingest docs
â”‚  â”œâ”€ services/
â”‚  â”‚  â”œâ”€ playback.py                # 20Hz CSV stream; 1Hz ticks
â”‚  â”‚  â”œâ”€ events.py                  # anomaly/phase detectors
â”‚  â”‚  â”œâ”€ planner.py                 # 1Hz loop â†’ compose â†’ call model
â”‚  â”‚  â”œâ”€ plan_schema.py             # Pydantic models (Plan/Decision/Metrics)
â”‚  â”‚  â”œâ”€ safety_gate.py             # redlines, confidence fusion
â”‚  â”‚  â””â”€ metrics.py                 # before/after, touchdown stats
â”‚  â”œâ”€ aria/
â”‚  â”‚  â”œâ”€ agent.py                   # OpenAI-compatible client (Groq/local)
â”‚  â”‚  â”œâ”€ prompts.py                 # system & few-shot, Chain-of-Draft style
â”‚  â”‚  â””â”€ memory/
â”‚  â”‚     â”œâ”€ schema.sql
â”‚  â”‚     â”œâ”€ store.py                # SQLite + FTS5 (episodic/semantic/docs)
â”‚  â”‚     â”œâ”€ embeddings.py           # local embeddings (e5-small / MiniLM)
â”‚  â”‚     â”œâ”€ retriever.py            # hybrid retrieval (FTS + embed + recency)
â”‚  â”‚     â”œâ”€ composer.py             # builds working memory; sections + weights
â”‚  â”‚     â”œâ”€ governor.py             # token budget, truncation, summarize
â”‚  â”‚     â”œâ”€ distill.py              # episodic â†’ lessons (semantic)
â”‚  â”‚     â””â”€ tools.py                # ReAct-lite: doc_search(), recall_lesson()
â”‚  â””â”€ tools/
â”‚     â”œâ”€ pdf_to_markdown_pymupdf.py # âœ… your light, fast converter
â”‚     â”œâ”€ docs_ingest.py             # chunk .md â†’ docs_fts + embeddings
â”‚     â””â”€ seed_from_csv.py           # telemetry sanity checks
â”‚
â”œâ”€ frontend/
â”‚  â”œâ”€ package.json
â”‚  â”œâ”€ next.config.mjs
â”‚  â”œâ”€ app/
â”‚  â”‚  â”œâ”€ layout.tsx
â”‚  â”‚  â””â”€ page.tsx                   # HUD + PlanPanel + Timeline
â”‚  â”œâ”€ components/
â”‚  â”‚  â”œâ”€ PlanPanel.tsx              # plan JSON card (risk, confidence)
â”‚  â”‚  â”œâ”€ Timeline.tsx               # SSE: anomalies/decisions
â”‚  â”‚  â””â”€ Gauges.tsx                 # alt, vspeed, airspeed, L/D, wind
â”‚  â””â”€ lib/
â”‚     â”œâ”€ ai.ts                      # Vercel AI SDK client helpers (stream)
â”‚     â””â”€ events.ts                  # SSE client for /events
â””â”€ scripts/
   â””â”€ record_demo.sh
```

---

## Quickstart

### 0) Prereqs
- Python 3.11+, Node 18+
- (Optional) Groq account + $25 promo: `OPENAIOSSGROQ2025`

### 1) Backend

```bash
cd backend
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
cp ../.env.example .env
# Set GROQ_API_KEY in .env (or run fully offline to use stubbed responses)
```
**Run**:

```bash
uvicorn app:app --reload --port 8000
```

### 2) Frontend

```bash
cd ../frontend
npm i
npm run dev
# http://localhost:3000
```

### 3) Play a scenario

```bash
# list scenarios
curl http://localhost:8000/scenarios
# start one
curl -X POST "http://localhost:8000/start?scenario=crosswind_baseline"
# stop
curl -X POST http://localhost:8000/stop
```

##### Scenarios included

landing_crosswind_baseline.csv â€” late flare â†’ hard landing (baseline)
landing_crosswind_lesson.csv â€” retrieved lesson â†’ earlier flare/larger base â†’ softer touchdown
landing_blackout_window.csv â€” lost-comms window; conservative hold/flare window
(You can generate these offline from a simulator and keep the CSVs small.)


## Environment

Create .env at repo root or backend/.env:

```bash

PORT=8000
WS_PATH=/ws/telemetry
TICK_HZ=20                       # playback rate
REASON_HZ=1                      # reasoning cadence

# Groq / GPT-OSS
GROQ_API_KEY=your_key_here
OPENAI_BASE_URL=https://api.groq.com/openai/v1
GPT_MODEL=openai/gpt-oss-20b     # use 120b for final hero clip if desired
```
---
## API overview

GET /scenarios â†’ available telemetry files
POST /start?scenario=NAME â†’ begin playback
POST /stop â†’ stop playback
WS /ws/telemetry â†’ stream {telemetry, plan?, decision?, metrics} updates
POST /plan/approve â†’ body: {plan_id, modification?}
POST /plan/reject â†’ body: {plan_id, reason}
POST /admin/memory/reset â†’ clear episodic/semantic (dev only)
POST /admin/docs/ingest â†’ (optional) load PDFs into FTS5
Plan JSON (example)


## Memory & reasoning

Episodic: append-only events (anomaly/decision/outcome) sampled ~1 Hz.
Semantic: distilled â€œlessons learnedâ€ bullets by phase.
Docs RAG: local FTS5 over Space Rider procedures/checklists.
Composer: compact prompt = recent events + lessons + top doc chunks + current telemetry.
Governor: when episodic grows, trigger distillation â†’ keep prompts lean.
Cadence: model called at 1 Hz or on anomaly; no chain-of-thought logged.

## Safety model

Redlines (tune to CSV): |bank| â‰¤ 20Â°, crosswind â‰¤ 8 m/s, flare 8â€“12 m AGL, vz@10m â‰¥ -2.5 m/s.
Safety Gate downgrades unsafe plans (e.g., â€œHold Patternâ€) and caps confidence.
HIL: humans Approve / Modify / Reject every plan; fallback Checklist Mode on LLM timeout.

## Notes

This repo ships with tiny CSVs; large media (PDFs/video) are ignored by git.
We used Groqâ€™s OpenAI-compatible endpoint for GPT-OSS;
Not affiliated with ESA; telemetry is synthetic for research/demo.


### Data Flow 

```bash
CSV (data/telemetry/landing_*.csv)  â† your generator (20 Hz rows + t)
         â”‚
         â–¼ 20 Hz
PlaybackService._run()
  â”œâ”€ SSE "tick" â†’ Frontend HUD
  â”œâ”€ MetricsTracker.update_from_telem()
  â”œâ”€ _maybe_emit_anomaly() â†’ SSE "anomaly" (when needed)
  â””â”€ every 1s:
        state_summary, query
           â”‚
           â–¼
        planner.tick()
           â”‚
           â”œâ”€ composer.build_working_memory()
           â”‚     â”œâ”€ episodic_recent(...)          (SQLite: episodic_log)
           â”‚     â”œâ”€ rephrased_guarded(query,k=4)  (SQLite: docs_rephrased + NLI vs docs)
           â”‚     â”‚     â””â”€ fallback docs(query)    (SQLite: docs)
           â”‚     â””â”€ lessons(query,k=1)            (SQLite: lessons)
           â”‚        â†³ governor trims to token budget
           â”‚
           â”œâ”€ prompts/system + few-shot + context
           â”œâ”€ agent.call_model()  (Groq GPT-OSS-20B)
           â”œâ”€ safety_gate.vet_plan()
           â”œâ”€ mem_store.episodic_append(kind="decision", data=plan)
           â””â”€ SSE "plan_proposed" (with references + latency)
                 â”‚
                 â””â”€ Frontend (PlanPanel): Approve/Modify/Reject â†’ POST /plan/...
                      â†³ mem_store.episodic_append(kind="decision", text="approved/...")
                      â†³ MetricsTracker may note result

... run continues until touchdown ...
  â”œâ”€ MetricsTracker.finish_run()
  â”œâ”€ SSE "metrics_update" (final)
  â”œâ”€ SSE "run_finished"
  â””â”€ (optional) distill.episodic â†’ lessons (SQLite)
        â†³ next run retrieves that new lesson automatically

```

SQLite roles
* docs â€” raw chunks from manuals/papers; FTS + embeddings; immutable.
* docs_rephrased â€” BeyondWeb-style lesson cards/Q&A/facts; preferred snippets; NLI-guarded vs docs.
* episodic_log â€” per-run timeline of events/decisions/outcomes; used for RECENT context.
* lessons â€” distilled, cross-run â€œwhat workedâ€; retrieved on future runs.

### What the model actually sees each second

state_summary (dict), ex:

```json
{
  "altitude_agl_m": 420.0,
  "vertical_speed_mps": -4.3,
  "wind_xy_mps": [2.1, 7.8],
  "phase": "final_approach",
  "bank_deg": 6.2
}
```
query (short string), ex:

"crosswind landing flare window procedure"

Working memory sections built by the composer:
* STATE: one-line summary
* RECENT: last few episodic events (anomalies/decisions)
* LESSON: top 1 long-term lesson if similar
* DOC: 1â€“4 rephrased snippets (NLI-guarded), else a couple of raw doc chunks

The governor trims that bundle to stay inside the token budget.
The LLM returns compact JSON: {action, reasoning, risk, confidence, references}.

â¸»
### to run the frontend 

1. Frontend deps
```bash
cd frontend
corepack enable                     # turn on the shims
pnpm -v                             # Corepack fetches the pinned pnpm version
pnpm install                        # uses the pinned pnpm for this project
```
2. Run both
```bash
pnpm dev
```

